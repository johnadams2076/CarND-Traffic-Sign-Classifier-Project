{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "## Deep Learning\n",
    "\n",
    "## Project: Build a Traffic Sign Recognition Classifier\n",
    "\n",
    "In this notebook, a template is provided for you to implement your functionality in stages, which is required to successfully complete this project. If additional code is required that cannot be included in the notebook, be sure that the Python code is successfully imported and included in your submission if necessary. \n",
    "\n",
    " **Note**: Once you have completed all of the code implementations, you need to finalize your work by exporting the iPython Notebook as an HTML document. Before exporting the notebook to html, all of the code cells need to have been run so that reviewers can see the final implementation and output. You can then export the notebook by using the menu above and navigating to  \\n\",\n",
    "    \"**File -> Download as -> HTML (.html)**. Include the finished document along with this notebook as your submission. \n",
    "\n",
    "In addition to implementing code, there is a writeup to complete. The writeup should be completed in a separate file, which can be either a markdown file or a pdf document. There is a [write up template](https://github.com/udacity/CarND-Traffic-Sign-Classifier-Project/blob/master/writeup_template.md) that can be used to guide the writing process. Completing the code template and writeup template will cover all of the [rubric points](https://review.udacity.com/#!/rubrics/481/view) for this project.\n",
    "\n",
    "The [rubric](https://review.udacity.com/#!/rubrics/481/view) contains \"Stand Out Suggestions\" for enhancing the project beyond the minimum requirements. The stand out suggestions are optional. If you decide to pursue the \"stand out suggestions\", you can include the code in this Ipython notebook and also discuss the results in the writeup file.\n",
    "\n",
    "\n",
    "**Note:** Code and Markdown cells can be executed using the **Shift + Enter** keyboard shortcut. In addition, Markdown cells can be edited by typically double-clicking the cell to enter edit mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 0: Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "\n",
    "# TODO: Fill this in based on where you saved the training and testing data\n",
    "\n",
    "training_file = './traffic_signs_data/train.p'\n",
    "validation_file = './traffic_signs_data/valid.p'\n",
    "testing_file = './traffic_signs_data/test.p'\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import cv2 as cv2\n",
    "\n",
    "def readTrafficSigns(rootpath):\n",
    "    '''Reads traffic sign data for German Traffic Sign Recognition Benchmark.\n",
    "\n",
    "    Arguments: path to the traffic sign data, for example './GTSRB/Training'\n",
    "    Returns:   list of images, list of corresponding labels'''\n",
    "    images = [] # images\n",
    "    labels = [] # corresponding labels\n",
    "    # loop over all 42 classes\n",
    "    for c in range(0,43):\n",
    "        prefix = rootpath + '/' + format(c, '05d') + '/' # subdirectory for class\n",
    "        gtFile = open(prefix + 'GT-'+ format(c, '05d') + '.csv') # annotations file\n",
    "        gtReader = csv.reader(gtFile, delimiter=';') # csv parser for annotations file\n",
    "        next(gtReader) # skip header\n",
    "        # loop over all images in current annotations file\n",
    "        for row in gtReader:\n",
    "            image = plt.imread(prefix + row[0])        \n",
    "            image = cv2.resize(image, (32, 32)) \n",
    "            images.append(image) # the 1th column is the filename\n",
    "            labels.append(row[7]) # the 8th column is the label\n",
    "        gtFile.close()\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read additional training data and concatenate to existing data.\n",
    "import numpy as np \n",
    "#from  sklearn.model_selection import train_test_split\n",
    "\n",
    "#more_data_path = './traffic_signs_data/GTSRB/Training/Images'\n",
    "#images, labels = readTrafficSigns(more_data_path)\n",
    "\n",
    "#images = np.asarray(images)\n",
    "#labels  = np.asarray(labels, dtype=np.int32)\n",
    "\n",
    "#images_train, images_test, labels_train, labels_test = train_test_split(images, labels, test_size=0.2, random_state=1)\n",
    "\n",
    "#images_train, images_valid, labels_train, labels_valid = train_test_split(images_train, labels_train, test_size=0.2, random_state=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize pre-augmented data\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import random\n",
    "import pandas\n",
    "from collections import Counter\n",
    "with tf.device('/cpu:0'):\n",
    "    df = pandas.read_csv('signnames.csv')\n",
    "    data = df.values\n",
    "\n",
    "%matplotlib inline  \n",
    "#%matplotlib notebook\n",
    "unique_tensor, idx_tensor, counts_tensor = tf.unique_with_counts(y_train)\n",
    "with tf.Session() as sess:\n",
    "    counts_train = sess.run(counts_tensor)\n",
    "    idx_train = sess.run(idx_tensor)\n",
    "count_aray = np.array(counts_train)\n",
    "x_axis = df['ClassId']\n",
    "y_pos = np.arange(len(x_axis))\n",
    "y_axis = [np.min(count_aray), np.max(count_aray)]\n",
    "plt.figure(figsize= [18, 10])\n",
    "plt.bar(x_axis, count_aray[:], align='center', alpha=0.5, width = 0.35\n",
    "       )\n",
    "plt.xticks(y_pos, x_axis)\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Class ID')\n",
    "plt.title('X_train class distribution')\n",
    "#fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "#print(fig_size)\n",
    "#plt.rcParams['figure.figsize'] = [10, 6]\n",
    "\n",
    "plt.show()\n",
    "unique_tensor, idx_tensor, counts_tensor = tf.unique_with_counts(y_valid)\n",
    "with tf.Session() as sess:\n",
    "    counts = sess.run(counts_tensor)\n",
    "count_aray = np.array(counts)\n",
    "x_axis = df['ClassId']\n",
    "y_pos = np.arange(len(x_axis))\n",
    "y_axis = [np.min(count_aray), np.max(count_aray)]\n",
    "plt.figure(figsize= [18, 10])\n",
    "plt.bar(x_axis, count_aray[:], align='center', alpha=0.5, width = 0.35\n",
    "       )\n",
    "plt.xticks(y_pos, x_axis)\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Class ID')\n",
    "plt.title('X_valid class distribution')\n",
    "#fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "#print(fig_size)\n",
    "#plt.rcParams['figure.figsize'] = [10, 6]\n",
    "\n",
    "plt.show()\n",
    "unique_tensor, idx_tensor, counts_tensor = tf.unique_with_counts(y_test)\n",
    "with tf.Session() as sess:\n",
    "    counts = sess.run(counts_tensor)\n",
    "count_aray = np.array(counts)\n",
    "x_axis = df['ClassId']\n",
    "y_pos = np.arange(len(x_axis))\n",
    "y_axis = [np.min(count_aray), np.max(count_aray)]\n",
    "plt.figure(figsize= [18, 10])\n",
    "plt.bar(x_axis, count_aray[:], align='center', alpha=0.5, width = 0.35\n",
    "       )\n",
    "plt.xticks(y_pos, x_axis)\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Class ID')\n",
    "plt.title('X_test class distribution')\n",
    "#fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "#print(fig_size)\n",
    "#plt.rcParams['figure.figsize'] = [10, 6]\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86430, 32, 32, 3) (86430,)\n"
     ]
    }
   ],
   "source": [
    "max_count = np.max(counts_train)\n",
    "n_classes = len(counts_train)\n",
    "X_train_aray = y_train_aray = []\n",
    "\n",
    "idx_temp_aray = np.array(np.nonzero(idx_train == 0))\n",
    "#idx_temp_aray = np.reshape(idx_temp_aray, [idx_temp_aray.shape[1]])\n",
    "idx_temp_aray = idx_temp_aray.T\n",
    "idx_temp_aray = np.reshape(idx_temp_aray, idx_temp_aray.shape[0])\n",
    "print(idx_temp_aray.shape)\n",
    "X_train_temp = X_train[idx_temp_aray]\n",
    "\n",
    "y_train_temp = y_train[idx_temp_aray]\n",
    "count_temp = len(y_train_temp)\n",
    "\n",
    "X_train_temp = np.tile(X_train_temp, ((max_count // count_temp) ,1, 1,1) )\n",
    "\n",
    "y_train_temp = np.tile(y_train_temp, ((max_count // count_temp)) )\n",
    "rem = max_count % count_temp\n",
    "if rem > 0:\n",
    "    idx_temp_aray = np.random.choice(idx_temp_aray, rem, replace=False)\n",
    "    X_train_temp = np.concatenate((X_train_temp, X_train[idx_temp_aray]), axis = 0)\n",
    "    y_train_temp = np.concatenate((y_train_temp, y_train[idx_temp_aray]), axis = 0)\n",
    "\n",
    "X_train_aray = X_train_temp\n",
    "y_train_aray = y_train_temp\n",
    "\n",
    "\n",
    "for i in range(1, n_classes):\n",
    "    idx_temp_aray = np.array(np.nonzero(idx_train == i))\n",
    "    idx_temp_aray = idx_temp_aray.T\n",
    "    idx_temp_aray = np.reshape(idx_temp_aray, idx_temp_aray.shape[0])\n",
    "    X_train_temp = X_train[idx_temp_aray]\n",
    "    y_train_temp = y_train[idx_temp_aray]\n",
    "    count_temp = len(X_train_temp)\n",
    "    X_train_temp = np.tile(X_train_temp, ((max_count // count_temp) ,1, 1,1) )\n",
    "    y_train_temp = np.tile(y_train_temp, ((max_count // count_temp)))\n",
    "    rem = max_count % count_temp\n",
    "    if rem > 0:\n",
    "        idx_temp_aray = np.random.choice(idx_temp_aray, rem, replace=False)\n",
    "        X_train_temp = np.concatenate((X_train_temp, X_train[idx_temp_aray]), axis = 0)\n",
    "        y_train_temp = np.concatenate((y_train_temp, y_train[idx_temp_aray]), axis = 0)\n",
    "        \n",
    "\n",
    "    X_train_aray = np.concatenate((X_train_aray, X_train_temp))\n",
    "\n",
    "    y_train_aray = np.concatenate((y_train_aray, y_train_temp))\n",
    "\n",
    "\n",
    "unique_tensor, idx_tensor, counts_tensor = tf.unique_with_counts(y_train_aray)\n",
    "with tf.Session() as sess:\n",
    "    counts_train = sess.run(counts_tensor)\n",
    "    idx_train = sess.run(idx_tensor)   \n",
    "max_count = np.max(counts_train)\n",
    "n_classes = len(counts_train)\n",
    "count_aray = np.array(counts_train)\n",
    "x_axis = df['ClassId']\n",
    "y_pos = np.arange(len(x_axis))\n",
    "y_axis = [np.min(count_aray), np.max(count_aray)]\n",
    "plt.figure(figsize= [18, 10])\n",
    "plt.bar(x_axis, count_aray[:], align='center', alpha=0.5, width = 0.35)\n",
    "plt.xticks(y_pos, x_axis)\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Class ID')\n",
    "plt.title('X_train class distribution')\n",
    "plt.show()\n",
    "plt.imshow(X_train_aray[86420])\n",
    "plt.show()\n",
    "y_train = y_train_aray\n",
    "X_train = X_train_aray\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(259290, 32, 32, 3) (259290,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#flipped_images = []\n",
    "#flipped_image_labels = []\n",
    "#shape = [X_train.shape[0], X_train.shape[1], X_train.shape[2], X_train.shape[3]]\n",
    "#x = tf.placeholder(dtype = X_train.dtype, shape = shape)\n",
    "#X_flipped_1 = tf.placeholder(dtype = tf.int32, shape = shape)\n",
    "#X_flipped_2 = tf.placeholder(dtype = tf.int32, shape = shape)\n",
    "data_aug_lim = 2010\n",
    "with tf.device('/cpu:0'):\n",
    "    x = X_train_tensor = tf.convert_to_tensor(X_train)\n",
    "    \n",
    "    X_train_aray = y_train_aray = []\n",
    "    #idx_temp_aray = tf.where(idx_train==0)\n",
    "    #print(idx_temp_aray)\n",
    "    #X_train_temp = tf.gather(X_train_tensor, idx_temp_aray)\n",
    "    idx_temp_aray = np.array(np.nonzero(idx_train == 0))\n",
    "    idx_temp_aray = idx_temp_aray.T\n",
    "    idx_temp_aray = np.reshape(idx_temp_aray, (-1))\n",
    "    #idx_temp_aray = np.reshape(idx_temp_aray, [idx_temp_aray.shape[1]])\n",
    "    idx_temp_aray = np.random.choice(idx_temp_aray, data_aug_lim, replace=False)\n",
    "    \n",
    "\n",
    "    X_train_temp = tf.gather(X_train_tensor, idx_temp_aray)\n",
    "    y_train_temp = y_train[idx_temp_aray]\n",
    "    #count_temp = len(y_train_temp)\n",
    "\n",
    "    X_flipped_1 = tf.cast(tf.image.flip_up_down(X_train_temp), X_train_tensor.dtype)\n",
    "    X_flipped_2 = tf.cast(tf.image.flip_left_right(X_train_temp),  X_train_tensor.dtype)\n",
    "    #X_train_temp = tf.tile(X_train_temp, (data_aug_lim,1, 1,1) )\n",
    "\n",
    "    #y_train_temp = tf.tile(y_train_temp, data_aug_lim)\n",
    "\n",
    "    X_train_aray = tf.concat((X_flipped_1, X_flipped_2), axis = 0)\n",
    "    y_train_aray = tf.concat((y_train_temp, y_train_temp), axis = 0)\n",
    "\n",
    "\n",
    "    for i in range(1, n_classes):\n",
    "        idx_temp_aray = np.array(np.nonzero(idx_train == i))\n",
    "        idx_temp_aray = idx_temp_aray.T\n",
    "        idx_temp_aray = np.reshape(idx_temp_aray, (-1))\n",
    "        X_train_temp =  tf.gather(X_train_tensor, idx_temp_aray)\n",
    "        y_train_temp = y_train[idx_temp_aray]\n",
    "        #count_temp = len(X_train_temp)\n",
    "        X_flipped_1 = tf.cast(tf.image.flip_up_down(X_train_temp), X_train_tensor.dtype)\n",
    "        X_flipped_2 = tf.cast(tf.image.flip_left_right(X_train_temp),  X_train_tensor.dtype)\n",
    "\n",
    "        X_train_aray = tf.concat((X_train_aray, X_flipped_1, X_flipped_2), axis = 0)\n",
    "        y_train_aray = tf.concat((y_train_aray, y_train_temp, y_train_temp), axis = 0)\n",
    "\n",
    "\n",
    "    X_train_aray = tf.concat((X_train_tensor, X_train_aray), axis = 0)\n",
    "    y_train_aray = tf.concat((y_train, y_train_aray), axis = 0)\n",
    "    \n",
    "            #for i in range(0,X_train.shape[0], 10000):\n",
    "        #   x = X_train[i]\n",
    "        #   y  = y_train[i]\n",
    "        #x = tf.placeholder(dtype = tf.float32, shape = shape)\n",
    "        #  flipped_images.append(tf.image.flip_up_down(x))\n",
    "        # flipped_image_labels.append(y)\n",
    "        # flipped_images.append(tf.image.flip_left_right(x))\n",
    "        #  flipped_image_labels.append(y)\n",
    "        # flipped_images.append(tf.image.random_flip_up_down(x))\n",
    "        # flipped_image_labels.append(y)\n",
    "        # flipped_images.append(tf.image.random_flip_left_right(x))\n",
    "        # flipped_image_labels.append(y)\n",
    "\n",
    "\n",
    "        #session.run(tf.global_variables_initializer())\n",
    "        #X_flipped_1 = session.run(X_flipped_1, feed_dict={x: X_train_tensor})\n",
    "        #X_flipped_2 = session.run(X_flipped_2, feed_dict={x: X_train_tensor})\n",
    "\n",
    "        #eval1 = X_flipped_1.eval(session)\n",
    "        #eval2 = X_flipped_2.eval(session)\n",
    "    #X_train_tensor = tf.concat((X_train_tensor, X_flipped_1, X_flipped_2), axis = 0)\n",
    "    #y_train_orig = y_train\n",
    "    #y_train = tf.concat((y_train_orig, y_train_orig[0:data_aug_lim], y_train_orig[0:data_aug_lim] ), axis = 0)\n",
    "    X_train_tensor = X_train_aray\n",
    "    y_train = y_train_aray\n",
    "    print(X_train_tensor.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(864300, 32, 32, 3) (864300,)\n"
     ]
    }
   ],
   "source": [
    "import skimage\n",
    "from skimage import transform\n",
    "shape = [X_train_tensor.shape[0], X_train_tensor.shape[1], X_train_tensor.shape[2], X_train_tensor.shape[3]]\n",
    "#angles_shape = [shape[0]]\n",
    "data_aug_lim = 2010\n",
    "#x = tf.placeholder(dtype = X_train.dtype, shape = shape)\n",
    "x = X_train_tensor\n",
    "#angles = tf.placeholder(dtype = tf.float32, shape = angles_shape)\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    \n",
    "    \n",
    "    unique_tensor, idx_tensor, counts_tensor = tf.unique_with_counts(y_train)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        #counts_train = sess.run(counts_tensor)\n",
    "        idx_train = sess.run(idx_tensor)\n",
    "        \n",
    "    X_train_aray = y_train_aray = []\n",
    "    \n",
    "    idx_temp_aray = np.array(np.nonzero(idx_train == 0))\n",
    "    idx_temp_aray = idx_temp_aray.T\n",
    "    idx_temp_aray = np.reshape(idx_temp_aray, (-1))\n",
    "    idx_temp_aray = np.random.choice(idx_temp_aray, data_aug_lim, replace=False)\n",
    "    \n",
    "\n",
    "    X_train_temp = tf.gather(X_train_tensor, idx_temp_aray)\n",
    "    y_train_temp = tf.gather(y_train, idx_temp_aray)\n",
    "    \n",
    "    \n",
    "    \n",
    "    angles_45 = np.full((data_aug_lim), 0.785398)\n",
    "    angles_90 = np.full((data_aug_lim), 1.5708)\n",
    "    angles_135 = np.full((data_aug_lim), 2.35619)\n",
    "    angles_180 = np.full((data_aug_lim), 3.14159)\n",
    "    angles_225 = np.full((data_aug_lim), 3.92699)\n",
    "    angles_270 = np.full((data_aug_lim), 4.79966)\n",
    "    angles_315 = np.full((data_aug_lim), 5.49779)\n",
    "\n",
    "    X_rotate_1 = tf.contrib.image.rotate(X_train_temp, angles_45)\n",
    "    X_rotate_2 = tf.contrib.image.rotate(X_train_temp, angles_90)\n",
    "    X_rotate_3 = tf.contrib.image.rotate(X_train_temp, angles_135)\n",
    "    X_rotate_4 = tf.contrib.image.rotate(X_train_temp, angles_180)\n",
    "    X_rotate_5 = tf.contrib.image.rotate(X_train_temp, angles_225)\n",
    "    X_rotate_6 = tf.contrib.image.rotate(X_train_temp, angles_270)\n",
    "    X_rotate_7 = tf.contrib.image.rotate(X_train_temp, angles_315)\n",
    "    \n",
    "    X_train_aray = tf.concat((X_rotate_1, X_rotate_2, X_rotate_3, X_rotate_4, X_rotate_5, X_rotate_6, X_rotate_7), axis=0)\n",
    "    y_train_aray = tf.concat((y_train_temp, y_train_temp, y_train_temp,  y_train_temp, y_train_temp, y_train_temp, y_train_temp ), axis=0)\n",
    "\n",
    "\n",
    "    for i in range(1, n_classes):\n",
    "        idx_temp_aray = np.array(np.nonzero(idx_train == i))\n",
    "        idx_temp_aray = idx_temp_aray.T\n",
    "        idx_temp_aray = np.reshape(idx_temp_aray, (-1))\n",
    "        idx_temp_aray = np.random.choice(idx_temp_aray, data_aug_lim, replace=False)\n",
    "\n",
    "\n",
    "        X_train_temp = tf.gather(X_train_tensor, idx_temp_aray)\n",
    "        y_train_temp = tf.gather(y_train, idx_temp_aray)\n",
    "        \n",
    "        X_rotate_1 = tf.contrib.image.rotate(X_train_temp, angles_45)\n",
    "        X_rotate_2 = tf.contrib.image.rotate(X_train_temp, angles_90)\n",
    "        X_rotate_3 = tf.contrib.image.rotate(X_train_temp, angles_135)\n",
    "        X_rotate_4 = tf.contrib.image.rotate(X_train_temp, angles_180)\n",
    "        X_rotate_5 = tf.contrib.image.rotate(X_train_temp, angles_225)\n",
    "        X_rotate_6 = tf.contrib.image.rotate(X_train_temp, angles_270)\n",
    "        X_rotate_7 = tf.contrib.image.rotate(X_train_temp, angles_315)\n",
    "        \n",
    "        X_train_aray = tf.concat((X_train_aray, X_rotate_1, X_rotate_2, X_rotate_3, X_rotate_4, X_rotate_5, X_rotate_6, X_rotate_7), axis=0)\n",
    "        y_train_aray = tf.concat((y_train_aray, y_train_temp, y_train_temp, y_train_temp,  y_train_temp, y_train_temp, y_train_temp, y_train_temp ), axis=0)\n",
    "\n",
    "        \n",
    "    X_train_aray = tf.concat((X_train_tensor, X_train_aray), axis = 0)\n",
    "    y_train_aray = tf.concat((y_train, y_train_aray), axis = 0)\n",
    "    #X_rotate_1 = skimage.transform.rotate(x, angle=45, mode='reflect')\n",
    "    #X_rotate_2 = skimage.transform.rotate(x, angle=90, mode='reflect')\n",
    "    #X_rotate_3 = skimage.transform.rotate(x, angle=135, mode='reflect')\n",
    "    #X_rotate_4 = skimage.transform.rotate(x, angle=180, mode='reflect')\n",
    "    #X_rotate_5 = skimage.transform.rotate(x, angle=225, mode='reflect')\n",
    "    #X_rotate_6 = skimage.transform.rotate(x, angle=270, mode='reflect')\n",
    "    #X_rotate_7 = skimage.transform.rotate(x, angle=315, mode='reflect')\n",
    "\n",
    "\n",
    "    #sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "    #angles_list =  np.concatenate((angles_45, angles_90, angles_135, angles_180, angles_225, angles_270, angles_315 )\n",
    "    #sess.run(X_rotate_1, feed_dict={x: X_train, angles:angles_45})\n",
    "    #sess.run([X_rotate_1, X_rotate_2, X_rotate_3, X_rotate_4, X_rotate_5, X_rotate_6, X_rotate_7], feed_dict={x: X_train, angles:angles_45})\n",
    "    #X_train_tensor = tf.concat((X_train_tensor, X_rotate_1, X_rotate_2, X_rotate_3, X_rotate_4, X_rotate_5, X_rotate_7), axis=0)\n",
    "    #y_train_orig = y_train\n",
    "    #y_train = tf.concat((y_train_orig, y_train_orig[0:data_aug_lim], y_train_orig[0:data_aug_lim], y_train_orig[0:data_aug_lim], y_train_orig[0:data_aug_lim], y_train_orig[0:data_aug_lim], y_train_orig[0:data_aug_lim]), axis=0)\n",
    "    #print(X_train_tensor.shape, y_train.shape)\n",
    "    #for i in range(X_train.shape[0]):\n",
    "    #img = X_train[i]\n",
    "    #y  = y_train[i]\n",
    "    #rot_90 = tf.image.rot90(img, k=1)\n",
    "\n",
    "    #rot_180 = tf.image.rot90(img, k=2)\n",
    "    #rot_270 = tf.image.rot90(img, k=3)\n",
    "    #rot_180 = tf.image.rot90(img, k=2)\n",
    "    # To rotate in any angle. In the example below, 'angles' is in radians\n",
    "\n",
    "    #shape = [batch, height, width, 3]\n",
    "    #y = tf.placeholder(dtype = tf.float32, shape = shape)\n",
    "    #rot_tf_180 = tf.contrib.image.rotate(y, angles=3.1415)\n",
    "\n",
    "    # Scikit-Image. 'angle' = Degrees. 'img' = Input Image\n",
    "    # For details about 'mode', checkout the interpolation section below.\n",
    "    #rotated_images.append()\n",
    "    #rotated_image_labels.append(y)\n",
    "    #rotated_images.append(skimage.transform.rotate(img, angle=90, mode='reflect'))\n",
    "    #rotated_image_labels.append(y)\n",
    "    #rotated_images.append(skimage.transform.rotate(img, angle=135, mode='reflect'))\n",
    "    #rotated_image_labels.append(y)\n",
    "    #rotated_images.append(skimage.transform.rotate(img, angle=180, mode='reflect'))\n",
    "    #rotated_image_labels.append(y)\n",
    "    #rotated_images.append(skimage.transform.rotate(img, angle=225, mode='reflect'))\n",
    "    #rotated_image_labels.append(y)\n",
    "    #rotated_images.append(skimage.transform.rotate(img, angle=270, mode='reflect'))\n",
    "    #rotated_image_labels.append(y)\n",
    "    #rotated_images.append(skimage.transform.rotate(img, angle=315, mode='reflect'))\n",
    "    # rotated_image_labels.append(y)\n",
    "    #X_train = np.concatenate((X_train, rotated_images))\n",
    "    X_train_tensor = X_train_aray\n",
    "    y_train = y_train_aray\n",
    "    print(X_train_tensor.shape, y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1210020, 32, 32, 3) (1210020,)\n"
     ]
    }
   ],
   "source": [
    "# Crop Image and resize to original height\n",
    "data_aug_lim = 2010\n",
    "with tf.device('/cpu:0'):\n",
    "    unique_tensor, idx_tensor, counts_tensor = tf.unique_with_counts(y_train)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        #counts_train = sess.run(counts_tensor)\n",
    "        idx_train = sess.run(idx_tensor)\n",
    "        \n",
    "    X_train_aray = y_train_aray = []\n",
    "    \n",
    "    idx_temp_aray = np.array(np.nonzero(idx_train == 0))\n",
    "    idx_temp_aray = idx_temp_aray.T\n",
    "    idx_temp_aray = np.reshape(idx_temp_aray, (-1))\n",
    "    idx_temp_aray = np.random.choice(idx_temp_aray, data_aug_lim, replace=False)\n",
    "    \n",
    "\n",
    "    X_train_temp = tf.gather(X_train_tensor, idx_temp_aray)\n",
    "    y_train_temp = tf.gather(y_train, idx_temp_aray)\n",
    "    \n",
    "    \n",
    "    original_size = (X_train_tensor.shape[1], X_train_tensor.shape[2])\n",
    "    crop_size = ( data_aug_lim, X_train_tensor.shape[1] // 2, X_train_tensor.shape[2] // 2,  X_train_tensor.shape[3])\n",
    "    seed = np.random.randint(1234)\n",
    "    x = X_train_tensor\n",
    "\n",
    "    # Crop random 1 \n",
    "    x_crop = tf.random_crop(X_train_temp, size = crop_size, seed = seed)\n",
    "    x1 = tf.cast(tf.image.resize_images(x_crop, size = original_size), X_train_tensor.dtype)\n",
    "\n",
    "    # Crop random 2\n",
    "    x_crop = tf.random_crop(X_train_temp, size = crop_size, seed = seed)\n",
    "    x2 = tf.cast(tf.image.resize_images(x_crop, size = original_size),  X_train_tensor.dtype)\n",
    "\n",
    "    # Crop random 3\n",
    "    x_crop = tf.random_crop(X_train_temp, size = crop_size, seed = seed)\n",
    "    x3 =  tf.cast(tf.image.resize_images(x_crop, size = original_size),  X_train_tensor.dtype)\n",
    "\n",
    "    # Crop random 4\n",
    "    x_crop = tf.random_crop(X_train_temp, size = crop_size, seed = seed)\n",
    "    x4 = tf.cast(tf.image.resize_images(x_crop, size = original_size),  X_train_tensor.dtype)\n",
    "\n",
    "    X_train_aray = tf.concat((x1, x2, x3, x4), axis = 0)\n",
    "    y_train_aray = tf.concat((y_train_temp, y_train_temp, y_train_temp, y_train_temp ), axis = 0) \n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(1, n_classes):\n",
    "        idx_temp_aray = np.array(np.nonzero(idx_train == i))\n",
    "        idx_temp_aray = idx_temp_aray.T\n",
    "        idx_temp_aray = np.reshape(idx_temp_aray, (-1))\n",
    "        idx_temp_aray = np.random.choice(idx_temp_aray, data_aug_lim, replace=False)\n",
    "\n",
    "\n",
    "        X_train_temp = tf.gather(X_train_tensor, idx_temp_aray)\n",
    "        y_train_temp = tf.gather(y_train, idx_temp_aray)\n",
    "\n",
    "        # Crop random 1 \n",
    "        x_crop = tf.random_crop(X_train_temp, size = crop_size, seed = seed)\n",
    "        x1 = tf.cast(tf.image.resize_images(x_crop, size = original_size), X_train_tensor.dtype)\n",
    "\n",
    "        # Crop random 2\n",
    "        x_crop = tf.random_crop(X_train_temp, size = crop_size, seed = seed)\n",
    "        x2 = tf.cast(tf.image.resize_images(x_crop, size = original_size),  X_train_tensor.dtype)\n",
    "\n",
    "        # Crop random 3\n",
    "        x_crop = tf.random_crop(X_train_temp, size = crop_size, seed = seed)\n",
    "        x3 =  tf.cast(tf.image.resize_images(x_crop, size = original_size),  X_train_tensor.dtype)\n",
    "\n",
    "        # Crop random 4\n",
    "        x_crop = tf.random_crop(X_train_temp, size = crop_size, seed = seed)\n",
    "        x4 = tf.cast(tf.image.resize_images(x_crop, size = original_size),  X_train_tensor.dtype)\n",
    "\n",
    "        X_train_aray = tf.concat((X_train_aray, x1, x2, x3, x4), axis = 0)\n",
    "        y_train_aray = tf.concat((y_train_aray, y_train_temp, y_train_temp, y_train_temp, y_train_temp ), axis = 0) \n",
    "     \n",
    "    X_train_aray = tf.concat((X_train_tensor, X_train_aray), axis = 0)\n",
    "    y_train_aray = tf.concat((y_train, y_train_aray), axis = 0)   \n",
    "        \n",
    "    #y_train_orig = y_train\n",
    "    #print(y_train_orig.shape, y_train_orig[0:data_aug_lim].shape)\n",
    "    #y_train = tf.concat((y_train_orig, y_train_orig[0:data_aug_lim], y_train_orig[0:data_aug_lim], y_train_orig[0:data_aug_lim], y_train_orig[0:data_aug_lim]), axis = 0) \n",
    "    X_train_tensor = X_train_aray\n",
    "    y_train = y_train_aray\n",
    "    print(X_train_tensor.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1555740, 32, 32, 3) (1555740,)\n"
     ]
    }
   ],
   "source": [
    "# pad_left, pad_right, pad_top, pad_bottom denote the pixel \n",
    "# displacement. Set one of them to the desired value and rest to 0\n",
    "with tf.device('/cpu:0'):\n",
    "    shape = [X_train_tensor.shape[0], X_train_tensor.shape[1], X_train_tensor.shape[2], X_train_tensor.shape[3]]\n",
    "    x = X_train_tensor\n",
    "    data_aug_lim = 2010\n",
    "    unique_tensor, idx_tensor, counts_tensor = tf.unique_with_counts(y_train)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        #counts_train = sess.run(counts_tensor)\n",
    "        idx_train = sess.run(idx_tensor)\n",
    "        \n",
    "    X_train_aray = y_train_aray = []\n",
    "    \n",
    "    idx_temp_aray = np.array(np.nonzero(idx_train == 0))\n",
    "    idx_temp_aray = idx_temp_aray.T\n",
    "    idx_temp_aray = np.reshape(idx_temp_aray, (-1))\n",
    "    idx_temp_aray = np.random.choice(idx_temp_aray, data_aug_lim, replace=False)\n",
    "    \n",
    "\n",
    "    X_train_temp = tf.gather(X_train_tensor, idx_temp_aray)\n",
    "    y_train_temp = tf.gather(y_train, idx_temp_aray)\n",
    "    \n",
    "    \n",
    "    pad_left = 50\n",
    "    pad_right = pad_top = pad_bottom = 0\n",
    "    # We use two functions to get our desired augmentation\n",
    "    x1 = tf.image.pad_to_bounding_box(X_train_temp, pad_top, pad_left, shape[1] + pad_bottom + pad_top, shape[2] + pad_right + pad_left)\n",
    "    x1 = tf.image.crop_to_bounding_box(x1, pad_bottom, pad_right, shape[1], shape[2])\n",
    "\n",
    "\n",
    "    pad_right = 50\n",
    "    pad_left = pad_top = pad_bottom = 0\n",
    "    # We use two functions to get our desired augmentation\n",
    "    x2 = tf.image.pad_to_bounding_box(X_train_temp, pad_top, pad_left, shape[1] + pad_bottom + pad_top, shape[2] + pad_right + pad_left)\n",
    "    x2 = tf.image.crop_to_bounding_box(x2, pad_bottom, pad_right, shape[1], shape[2])\n",
    "\n",
    "\n",
    "    pad_top = 50\n",
    "    pad_left = pad_right = pad_bottom = 0\n",
    "    # We use two functions to get our desired augmentation\n",
    "    x3 = tf.image.pad_to_bounding_box(X_train_temp, pad_top, pad_left, shape[1] + pad_bottom + pad_top, shape[2] + pad_right + pad_left)\n",
    "    x3 = tf.image.crop_to_bounding_box(x3, pad_bottom, pad_right, shape[1], shape[2])\n",
    "\n",
    "\n",
    "    pad_bottom = 50\n",
    "    pad_left = pad_top = pad_right = 0\n",
    "    # We use two functions to get our desired augmentation\n",
    "    x4 = tf.image.pad_to_bounding_box(X_train_temp, pad_top, pad_left, shape[1] + pad_bottom + pad_top, shape[2] + pad_right + pad_left)\n",
    "    x4 = tf.image.crop_to_bounding_box(x4, pad_bottom, pad_right, shape[1], shape[2])\n",
    "\n",
    "\n",
    "    X_train_aray = tf.concat((x1, x2, x3, x4), axis = 0)\n",
    "    y_train_aray = tf.concat((y_train_temp, y_train_temp, y_train_temp, y_train_temp), axis = 0)\n",
    "    \n",
    "    for i in range(1, n_classes):\n",
    "        idx_temp_aray = np.array(np.nonzero(idx_train == i))\n",
    "        idx_temp_aray = idx_temp_aray.T\n",
    "        idx_temp_aray = np.reshape(idx_temp_aray, (-1))\n",
    "        idx_temp_aray = np.random.choice(idx_temp_aray, data_aug_lim, replace=False)\n",
    "\n",
    "\n",
    "        X_train_temp = tf.gather(X_train_tensor, idx_temp_aray)\n",
    "        y_train_temp = tf.gather(y_train, idx_temp_aray)\n",
    "        \n",
    "         \n",
    "        pad_left = 50\n",
    "        pad_right = pad_top = pad_bottom = 0\n",
    "        # We use two functions to get our desired augmentation\n",
    "        x1 = tf.image.pad_to_bounding_box(X_train_temp, pad_top, pad_left, shape[1] + pad_bottom + pad_top, shape[2] + pad_right + pad_left)\n",
    "        x1 = tf.image.crop_to_bounding_box(x1, pad_bottom, pad_right, shape[1], shape[2])\n",
    "\n",
    "\n",
    "        pad_right = 50\n",
    "        pad_left = pad_top = pad_bottom = 0\n",
    "        # We use two functions to get our desired augmentation\n",
    "        x2 = tf.image.pad_to_bounding_box(X_train_temp, pad_top, pad_left, shape[1] + pad_bottom + pad_top, shape[2] + pad_right + pad_left)\n",
    "        x2 = tf.image.crop_to_bounding_box(x2, pad_bottom, pad_right, shape[1], shape[2])\n",
    "\n",
    "\n",
    "        pad_top = 50\n",
    "        pad_left = pad_right = pad_bottom = 0\n",
    "        # We use two functions to get our desired augmentation\n",
    "        x3 = tf.image.pad_to_bounding_box(X_train_temp, pad_top, pad_left, shape[1] + pad_bottom + pad_top, shape[2] + pad_right + pad_left)\n",
    "        x3 = tf.image.crop_to_bounding_box(x3, pad_bottom, pad_right, shape[1], shape[2])\n",
    "\n",
    "\n",
    "        pad_bottom = 50\n",
    "        pad_left = pad_top = pad_right = 0\n",
    "        # We use two functions to get our desired augmentation\n",
    "        x4 = tf.image.pad_to_bounding_box(X_train_temp, pad_top, pad_left, shape[1] + pad_bottom + pad_top, shape[2] + pad_right + pad_left)\n",
    "        x4 = tf.image.crop_to_bounding_box(x4, pad_bottom, pad_right, shape[1], shape[2])\n",
    "\n",
    "\n",
    "        X_train_aray = tf.concat((X_train_aray, x1, x2, x3, x4), axis = 0)\n",
    "        y_train_aray = tf.concat((y_train_aray, y_train_temp, y_train_temp, y_train_temp, y_train_temp), axis = 0)\n",
    "\n",
    "    X_train_aray = tf.concat((X_train_tensor, X_train_aray), axis = 0)\n",
    "    y_train_aray = tf.concat((y_train, y_train_aray), axis = 0)   \n",
    "        \n",
    "    #y_train_orig = y_train\n",
    "    #y_train = tf.concat((y_train_orig, y_train_orig[0:data_aug_lim], y_train_orig[0:data_aug_lim], y_train_orig[0:data_aug_lim], y_train_orig[0:data_aug_lim]), axis = 0)  \n",
    "    X_train_tensor = X_train_aray\n",
    "    y_train = y_train_aray\n",
    "    print(X_train_tensor.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1901460, 32, 32, 3) (1901460,)\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    #gaussian_images = []\n",
    "    #gaussian_image_labels = []\n",
    "    shape = [X_train_tensor.shape[0], X_train_tensor.shape[1], X_train_tensor.shape[2], X_train_tensor.shape[3]]\n",
    "    #x = tf.placeholder(dtype = tf.float32, shape = shape)\n",
    "    X_train_tensor = tf.cast(X_train_tensor, dtype=tf.float32)\n",
    "    # Adding Gaussian noise\n",
    "    #batch_size = 10200\n",
    "    #iter_max = shape[0] // batch_size\n",
    "    #noise1_aray = []\n",
    "    #noise2_aray = []\n",
    "    #noise3_aray = []\n",
    "    #noise4_aray = []\n",
    "\n",
    "    data_aug_lim = 2010\n",
    "    unique_tensor, idx_tensor, counts_tensor = tf.unique_with_counts(y_train)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        #counts_train = sess.run(counts_tensor)\n",
    "        idx_train = sess.run(idx_tensor)\n",
    "        \n",
    "    X_train_aray = y_train_aray = []\n",
    "    \n",
    "    idx_temp_aray = np.array(np.nonzero(idx_train == 0))\n",
    "    idx_temp_aray = idx_temp_aray.T\n",
    "    idx_temp_aray = np.reshape(idx_temp_aray, (-1))\n",
    "    idx_temp_aray = np.random.choice(idx_temp_aray, data_aug_lim, replace=False)\n",
    "    \n",
    "\n",
    "    X_train_temp = tf.gather(X_train_tensor, idx_temp_aray)\n",
    "    y_train_temp = tf.gather(y_train, idx_temp_aray)\n",
    "    \n",
    "    #for i in range(iter_max):\n",
    "    #x_temp = x[(i * batch_size):((i+1) * batch_size)]\n",
    "    x_temp  = X_train_temp\n",
    "    noise1_shape = tf.random_normal(shape=tf.shape(x_temp), mean=0, stddev=1, dtype=x_temp.dtype)\n",
    "    noise1 = tf.add(x_temp, noise1_shape)\n",
    "    #noise1_aray.append(noise1)\n",
    "\n",
    "    noise2_shape = tf.random_normal(shape=tf.shape(x_temp), mean=0, stddev=1, dtype=x_temp.dtype)\n",
    "    noise2 = tf.add(x_temp, noise2_shape)\n",
    "    #noise2_aray.append(noise2)\n",
    "\n",
    "    noise3_shape = tf.random_normal(shape=tf.shape(x_temp), mean=0, stddev=1, dtype=x_temp.dtype)\n",
    "    noise3 = tf.add(x_temp, noise3_shape)\n",
    "    #noise3_aray.append(noise3)\n",
    "\n",
    "    noise4_shape = tf.random_normal(shape=tf.shape(x_temp), mean=0, stddev=1, dtype=x_temp.dtype)\n",
    "    noise4 = tf.add(x_temp, noise4_shape)\n",
    "    \n",
    "    X_train_aray = tf.concat((noise1, noise2, noise3, noise4), axis=0)\n",
    "    y_train_aray = tf.concat((y_train_temp, y_train_temp, y_train_temp, y_train_temp), axis=0 )\n",
    "    \n",
    "    \n",
    "    for i in range(1, n_classes):\n",
    "        idx_temp_aray = np.array(np.nonzero(idx_train == i))\n",
    "        idx_temp_aray = idx_temp_aray.T\n",
    "        idx_temp_aray = np.reshape(idx_temp_aray, (-1))\n",
    "        idx_temp_aray = np.random.choice(idx_temp_aray, data_aug_lim, replace=False)\n",
    "\n",
    "\n",
    "        X_train_temp = tf.gather(X_train_tensor, idx_temp_aray)\n",
    "        y_train_temp = tf.gather(y_train, idx_temp_aray)\n",
    "        \n",
    "        x_temp  = X_train_temp\n",
    "        noise1_shape = tf.random_normal(shape=tf.shape(x_temp), mean=0, stddev=1, dtype=x_temp.dtype)\n",
    "        noise1 = tf.add(x_temp, noise1_shape)\n",
    "        #noise1_aray.append(noise1)\n",
    "\n",
    "        noise2_shape = tf.random_normal(shape=tf.shape(x_temp), mean=0, stddev=1, dtype=x_temp.dtype)\n",
    "        noise2 = tf.add(x_temp, noise2_shape)\n",
    "        #noise2_aray.append(noise2)\n",
    "\n",
    "        noise3_shape = tf.random_normal(shape=tf.shape(x_temp), mean=0, stddev=1, dtype=x_temp.dtype)\n",
    "        noise3 = tf.add(x_temp, noise3_shape)\n",
    "        #noise3_aray.append(noise3)\n",
    "\n",
    "        noise4_shape = tf.random_normal(shape=tf.shape(x_temp), mean=0, stddev=1, dtype=x_temp.dtype)\n",
    "        noise4 = tf.add(x_temp, noise4_shape)\n",
    "\n",
    "        X_train_aray = tf.concat((X_train_aray, noise1, noise2, noise3, noise4), axis=0)\n",
    "        y_train_aray = tf.concat((y_train_aray, y_train_temp, y_train_temp, y_train_temp, y_train_temp), axis=0 )\n",
    "        \n",
    "    X_train_aray = tf.concat((X_train_tensor, X_train_aray), axis = 0)\n",
    "    y_train_aray = tf.concat((y_train, y_train_aray), axis = 0)         \n",
    "    \n",
    "    #noise4_aray.append(noise4)\n",
    "    #noise1_aray = tf.reshape(noise1_aray, shape)    \n",
    "    #noise2_aray = tf.reshape(noise2_aray, shape)   \n",
    "    #noise3_aray = tf.reshape(noise3_aray, shape)   \n",
    "    #noise4_aray = tf.reshape(noise4_aray, shape)   \n",
    "\n",
    "    #X_train_tensor = tf.concat((x, noise1_aray, noise2_aray, noise3_aray, noise4_aray), axis=0)\n",
    "    \n",
    "    #X_train_tensor = tf.concat((x, noise1, noise2, noise3, noise4), axis=0)\n",
    "    #print(np.array(temp_noise).shape[1])\n",
    "    #X_train_tensor = tf.concat((x, temp_noise[0]), axis = 0)\n",
    "    #y_train_orig = y_train\n",
    "    #y_train = tf.concat((y_train_orig, y_train_orig[0:data_aug_lim], y_train_orig[0:data_aug_lim], y_train_orig[0:data_aug_lim], y_train_orig[0:data_aug_lim]) , axis = 0)     \n",
    "    X_train_tensor = X_train_aray\n",
    "    y_train = y_train_aray  \n",
    "    print(X_train_tensor.shape, y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = X_train_tensor\n",
    "#X_train = tf.convert_to_tensor(X_train)\n",
    "#images_train, images_test, labels_train, labels_test \n",
    "#    = train_test_split(images, labels, test_size=0.2, random_state=1)\n",
    "\n",
    "#images_train, images_valid, labels_train, labels_valid \n",
    "#    = train_test_split(images_train, labels_train, test_size=0.2, random_state=1)\n",
    "#X_train = np.concatenate((X_train, images_train))\n",
    "#y_train = np.concatenate((y_train, labels_train))\n",
    "\n",
    "#X_valid = np.concatenate((X_valid, images_valid))\n",
    "#y_valid = np.concatenate((y_valid, labels_valid))\n",
    "\n",
    "#X_test = np.concatenate((X_test, images_test))\n",
    "#y_test = np.concatenate((y_test, labels_test))\n",
    "#print(X_train.shape, X_valid.shape, X_test.shape)\n",
    "#print(y_train.shape, y_valid.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1: Dataset Summary & Exploration\n",
    "\n",
    "The pickled data is a dictionary with 4 key/value pairs:\n",
    "\n",
    "- `'features'` is a 4D array containing raw pixel data of the traffic sign images, (num examples, width, height, channels).\n",
    "- `'labels'` is a 1D array containing the label/class id of the traffic sign. The file `signnames.csv` contains id -> name mappings for each id.\n",
    "- `'sizes'` is a list containing tuples, (width, height) representing the original width and height the image.\n",
    "- `'coords'` is a list containing tuples, (x1, y1, x2, y2) representing coordinates of a bounding box around the sign in the image. **THESE COORDINATES ASSUME THE ORIGINAL IMAGE. THE PICKLED DATA CONTAINS RESIZED VERSIONS (32 by 32) OF THESE IMAGES**\n",
    "\n",
    "Complete the basic data summary below. Use python, numpy and/or pandas methods to calculate the data summary rather than hard coding the results. For example, the [pandas shape method](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.shape.html) might be useful for calculating some of the summary results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide a Basic Summary of the Data Set Using Python, Numpy and/or Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 1901460\n",
      "Number of testing examples = 12630\n",
      "Image data shape = (Dimension(32), Dimension(32))\n",
      "Number of classes = 43\n",
      "Number of training examples for labels (1901460,)\n",
      "Training data shape (1901460, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "### Replace each question mark with the appropriate value. \n",
    "### Use python, pandas or numpy methods rather than hard coding the results\n",
    "\n",
    "import pandas\n",
    "with tf.device('/cpu:0'):\n",
    "    # TODO: Number of training examples\n",
    "    n_train = X_train_tensor.shape[0]\n",
    "\n",
    "    # TODO: Number of validation examples\n",
    "    n_validation = X_valid.shape[0]\n",
    "\n",
    "    # TODO: Number of testing examples.\n",
    "    n_test = X_test.shape[0]\n",
    "\n",
    "    # TODO: What's the shape of an traffic sign image?\n",
    "    image_shape = X_train_tensor.shape[1], X_train_tensor.shape[2]\n",
    "\n",
    "    # TODO: How many unique classes/labels there are in the dataset.\n",
    "    unique_tensor, idx_tensor, counts_tensor = tf.unique_with_counts(y_train)\n",
    "    n_classes = tf.size(unique_tensor)\n",
    "    with tf.Session() as sess:\n",
    "        n_classes = sess.run(n_classes)\n",
    "        counts = sess.run(counts_tensor)\n",
    "\n",
    "    #tf.bincount(tf.cast(y_train, dtype=tf.int32))\n",
    "    print(\"Number of training examples =\", n_train)\n",
    "    print(\"Number of testing examples =\", n_test)\n",
    "    print(\"Image data shape =\", image_shape)\n",
    "    print(\"Number of classes =\", n_classes)\n",
    "    print(\"Number of training examples for labels\", y_train.shape)\n",
    "    print(\"Training data shape\", X_train_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import os\n",
    "session_conf = tf.ConfigProto(\n",
    "    device_count={'CPU' : 1, 'GPU' : 0},\n",
    "    allow_soft_placement=True,\n",
    "    log_device_placement=False\n",
    ")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = ''\n",
    "with tf.device('/cpu:0'):\n",
    "    #X_train_dataset = tf.data.Dataset.from_tensor_slices(X_train_tensor)\n",
    "    #X_train_dataset = X_train_dataset.prefetch(1)\n",
    "    #iter = X_train_dataset.make_initializable_iterator()\n",
    "    #el = iter.get_next()\n",
    "    X_train_temp = X_train_tensor\n",
    "    y_train_temp = y_train\n",
    "    with tf.Session(config = session_conf) as sess:    \n",
    "        #sess.run(iter.initializer)\n",
    "        X_train_display = sess.run(X_train_temp)\n",
    "        y_train_display = sess.run(y_train_temp)\n",
    "        print(X_train_display[0])\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include an exploratory visualization of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the German Traffic Signs Dataset using the pickled file(s). This is open ended, suggestions include: plotting traffic sign images, plotting the count of each sign, etc. \n",
    "\n",
    "The [Matplotlib](http://matplotlib.org/) [examples](http://matplotlib.org/examples/index.html) and [gallery](http://matplotlib.org/gallery.html) pages are a great resource for doing visualizations in Python.\n",
    "\n",
    "**NOTE:** It's recommended you start with something simple first. If you wish to do more, come back to it after you've completed the rest of the sections. It can be interesting to look at the distribution of classes in the training, validation and test set. Is the distribution the same? Are there more examples of some classes than others?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration visualization code goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "# Visualizations will be shown in the notebook.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import random\n",
    "from collections import Counter\n",
    "with tf.device('/cpu:0'):\n",
    "    df = pandas.read_csv('signnames.csv')\n",
    "    data = df.values\n",
    "\n",
    "    #f, axarr = plt.subplots(4, 1)\n",
    "\n",
    "    #batch_size = 34799\n",
    "\n",
    "    arr_rand = [0, 1, 2, 3, 4, 5]\n",
    "    secure_random = random.SystemRandom()\n",
    "    step = secure_random.choice(arr_rand)\n",
    "\n",
    "    run_options = tf.RunOptions(report_tensor_allocations_upon_oom = True)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        #y_train_output = sess.run([y_train],  options=run_options)\n",
    "\n",
    "        #y_train_output = tf.cast(y_train_output, tf.int32)\n",
    "        shape = [X_train_display.shape[0], X_train_display.shape[1], X_train_display.shape[2], X_train_display.shape[3]]\n",
    "        #X_train_np = []\n",
    "        #X_train_tensor_output = sess.run([X_train_tensor])\n",
    "        #for i in range(X_train_tensor.shape[0]):\n",
    "            #X_train_tensor_output = X_train_tensor[i]\n",
    "            #print(X_train_tensor_output.shape)\n",
    "            #X_train_np_out= sess.run([X_train_tensor_output],  options=run_options)\n",
    "           # X_train_np = np.concat(X_train_np, X_train_np_out)\n",
    "        #X_train_tensor_output_1_5 = sess.run([X_train_tensor])\n",
    "        #X_train_tensor_output = sess.run([X_train_tensor])\n",
    "        #X_train_tensor_output = np.array(X_train_tensor_output).T\n",
    "        #print(X_train_np.shape)\n",
    "\n",
    "        #y_train_output = np.array(y_train_output)\n",
    "        y_train_output = tf.cast(y_train, dtype=tf.int32)\n",
    "        y_train_output = sess.run([ y_train_output],  options=run_options)\n",
    "        y_train_output = np.array(y_train_output).T\n",
    "        print(y_train_output.shape)\n",
    "        X_train_tensor = tf.cast(X_train_tensor, dtype=np.uint8)\n",
    "        count_aray = []\n",
    "        for j in range(len(data)):\n",
    "            count = counts[data[j][0]]\n",
    "            count_aray.append(count)\n",
    "            print('Label:',data[j][0],\"-\", data[j][1],\", Count:\",count)\n",
    "            \n",
    "  \n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "#%matplotlib notebook\n",
    "x_axis = df['ClassId']\n",
    "y_pos = np.arange(len(x_axis))\n",
    "y_axis = [np.min(count_aray), np.max(count_aray)]\n",
    "print(x_axis.shape, np.array(count_aray).shape)\n",
    "plt.figure(figsize= [18, 10])\n",
    "plt.bar(x_axis, count_aray[:], align='center', alpha=0.5, width = 0.35\n",
    "       )\n",
    "plt.xticks(y_pos, x_axis)\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Class ID')\n",
    "plt.title('X_train class distribution')\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "print(fig_size)\n",
    "#plt.rcParams['figure.figsize'] = [10, 6]\n",
    "\n",
    "\n",
    "print(X_train.shape\n",
    "     )\n",
    "\n",
    "plt.show()\n",
    "plt.imshow(X_train_display[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "%matplotlib inline \n",
    "for i in arr_rand:\n",
    "        print(y_train_output[i][0], X_train_display[i])\n",
    "        image = X_train_display[i]\n",
    "        #print(image)\n",
    "        count = counts[y_train_output[i][0]]\n",
    "        #image = sess.run([X_train_tensor[i]])\n",
    "        #print(image)\n",
    "        print('Label:',y_train_output[i][0],\"-\", data[y_train_output[i][0]][1],\", Count:\",count)\n",
    "        #axarr[j].imshow(image)\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "        #j+=1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Step 2: Design and Test a Model Architecture\n",
    "\n",
    "Design and implement a deep learning model that learns to recognize traffic signs. Train and test your model on the [German Traffic Sign Dataset](http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset).\n",
    "\n",
    "The LeNet-5 implementation shown in the [classroom](https://classroom.udacity.com/nanodegrees/nd013/parts/fbf77062-5703-404e-b60c-95b78b2f3f9e/modules/6df7ae49-c61c-4bb2-a23e-6527e69209ec/lessons/601ae704-1035-4287-8b11-e2c2716217ad/concepts/d4aca031-508f-4e0b-b493-e7b706120f81) at the end of the CNN lesson is a solid starting point. You'll have to change the number of classes and possibly the preprocessing, but aside from that it's plug and play! \n",
    "\n",
    "With the LeNet-5 solution from the lecture, you should expect a validation set accuracy of about 0.89. To meet specifications, the validation set accuracy will need to be at least 0.93. It is possible to get an even higher accuracy, but 0.93 is the minimum for a successful project submission. \n",
    "\n",
    "There are various aspects to consider when thinking about this problem:\n",
    "\n",
    "- Neural network architecture (is the network over or underfitting?)\n",
    "- Play around preprocessing techniques (normalization, rgb to grayscale, etc)\n",
    "- Number of examples per label (some have more than others).\n",
    "- Generate fake data.\n",
    "\n",
    "Here is an example of a [published baseline model on this problem](http://yann.lecun.com/exdb/publis/pdf/sermanet-ijcnn-11.pdf). It's not required to be familiar with the approach used in the paper but, it's good practice to try to read papers like these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process the Data Set (normalization, grayscale, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimally, the image data should be normalized so that the data has mean zero and equal variance. For image data, `(pixel - 128)/ 128` is a quick way to approximately normalize the data and can be used in this project. \n",
    "\n",
    "Other pre-processing steps are optional. You can try different techniques to see if it improves performance. \n",
    "\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://www.kaggle.com\n",
    "def vtoimg(v):\n",
    "     return np.array(np.clip(v, 0, 255), dtype=np.uint8).reshape(3,32,32).transpose([1,2,0])  \n",
    "# From https://www.kaggle.com    \n",
    "def whiten(pca, vec):\n",
    "    QQ = np.dot(vec - pca.mean_, pca.components_.T)\n",
    "    return np.dot(QQ / pca.singular_values_, pca.components_) * np.sqrt(60000) * 64 + 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1901460, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "### Preprocess the data here. It is required to normalize the data. Other preprocessing steps could include \n",
    "### converting to grayscale, etc.\n",
    "### Feel free to use as many code cells as needed.\n",
    "import cv2 as cv2 \n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    gc.collect()\n",
    "    # PCA / ZCA whitening\n",
    "    #from sklearn.decomposition import PCA\n",
    "    #pca = PCA(n_components=400, random_state=0, svd_solver='randomized')\n",
    "    #num_examples, nx, ny, channels = X_train.shape\n",
    "\n",
    "    #        np_X_train = X_train.eval(sess) \n",
    "     #       pca.fit(np_X_train)\n",
    "\n",
    "    #for i in range(X_train.shape[0]):\n",
    "     #   X_train = vtoimg(whiten(pca, X_train[i]))\n",
    "    #    X_valid = vtoimg(whiten(pca, X_valid[i]))\n",
    "    #    X_test = vtoimg(whiten(pca, X_test[i]))\n",
    "    #with tf.Session() as sess:\n",
    "    n_samp, nx, ny, channels = X_train_tensor.shape\n",
    "        #X_train = sess.run(X_train)\n",
    "    #print(X_train.dtype)\n",
    "    #n_samp_float = tf.cast((n_samp), tf.float32)\n",
    "    #n_samp_float_mod = n_samp_float * tf.cast((nx), tf.float32) * tf.cast((ny), tf.float32)\n",
    "    #channels = tf.cast((channels), tf.float32)\n",
    "    #X_train = tf.cast(X_train, tf.float32)\n",
    "    #X_train_mod = tf.reshape(X_train, [n_samp_float_mod, channels])\n",
    "    X_train_tensor = tf.cast(X_train_tensor, tf.float32)\n",
    "\n",
    "    X_valid = tf.cast(X_valid, tf.float32)\n",
    "    X_test = tf.cast(X_test, tf.float32)\n",
    "    # Convert to grayscale\n",
    "    #gray_aray =  tf.cast([0.2989, 0.5870, 0.1140],tf.float32 )\n",
    "    #gray_aray = tf.transpose(gray_aray)\n",
    "    #print(gray_aray.shape)\n",
    "    #train_temp = tf.dot(X_train_tensor, gray_tran)\n",
    "    #_train_temp = tf.multiply(X_train_tensor, tf.cast(gray_tran),tf.float32)\n",
    "    #print(X_train_temp.shape)\n",
    "    #X_train_mod = tf.reduce_sum(X_train_temp, 0)\n",
    "    #X_train_mod= tf.matmul(X_train_tensor, gray_tran)\n",
    "    #X_train_mod = np.dot(X_train_tensor, gray_aray )\n",
    "    #X_train_mod = tf.reshape(n_samp, nx, ny)\n",
    "    #X_valid_mod= (np.dot(X_valid, [0.2989, 0.5870, 0.1140]))\n",
    "    #X_test_mod= (np.dot(X_test, [0.2989, 0.5870, 0.1140]))\n",
    "    #X_train_mod = sess.run(X_train_mod)\n",
    "    #np_X_train = X_train_mod.eval(sess) \n",
    "    #print(X_train_mod.shape)\n",
    "    #batch_size = 102350\n",
    "    # = (X_train_tensor.shape[0], X_train_tensor.shape[1], X_train_tensor.shape[2], X_train_tensor.shape[3])\n",
    "    #iter_max = X_train_tensor.shape[0] // batch_size\n",
    "    #X_train_mod_aray = []\n",
    "    #print(iter_max)    \n",
    "    #x_temp = X_train_tensor[0:batch_size]\n",
    "    #gray_scale_img_concat = tf.image.rgb_to_grayscale(x_temp)\n",
    "\n",
    "    #for i in range(1,iter_max):\n",
    "        #x_temp = X_train_tensor[(i * batch_size):((i+1) * batch_size)]\n",
    "\n",
    "        #gray_scale_img_concat = tf.concat((gray_scale_img_concat, gray_scale_img), axis = 0)\n",
    "    #X_train = gray_scale_img_concat\n",
    "  \n",
    "    X_train = tf.image.rgb_to_grayscale(X_train_tensor)\n",
    "    X_valid = tf.image.rgb_to_grayscale(X_valid)\n",
    "    X_test = tf.image.rgb_to_grayscale(X_test)\n",
    "    \n",
    "    print(X_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.train.normalized Tensor(\"strided_slice:0\", shape=(32, 32, 1), dtype=float32, device=/device:CPU:0) (1901460, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "with tf.device('/cpu:0'):\n",
    "    # Normalize training data.\n",
    "    X_train = tf.divide(tf.subtract(X_train, 128), 128)\n",
    "    print(\"X.train.normalized\", X_train[0], X_train.shape)\n",
    "\n",
    "\n",
    "\n",
    "    # Normalize validation data.\n",
    "    X_valid = tf.divide(tf.subtract(X_valid, 128), 128)\n",
    "    #nsamples, nx, ny, channels = X_valid_mod.get_shape()\n",
    "    #d2_valid_dataset = tf.reshape(X_valid_mod, ((nsamples,nx*ny*channels)))\n",
    "    #X_valid = normalize(d2_valid_dataset)\n",
    "    #X_valid =  tf.reshape(X_valid.reshape,((nsamples,nx,ny,1)))\n",
    "\n",
    "    # Normalize test data.\n",
    "    X_test = tf.divide(tf.subtract(X_test, 128), 128)\n",
    "    #nsamples, nx, ny, channels = X_test_mod.get_shape()\n",
    "    #d2_test_dataset = tf.reshape(X_test_mod((nsamples,nx*ny*channels)))\n",
    "    #X_test = normalize(d2_test_dataset)\n",
    "    #X_test = tf.reshape(X_test((nsamples,nx,ny,1)))\n",
    "\n",
    "    # Histogram Equalizer\n",
    "    #X_train = cv2.equalizeHist(X_train)\n",
    "    #X_valid = cv2.equalizeHist(X_valid)\n",
    "    #X_test = cv2.equalizeHist(X_test)\n",
    "\n",
    "\n",
    "    from sklearn.utils import shuffle\n",
    "    # Shuffle the training data.\n",
    "    #X_train = tf.random_shuffle(X_train)\n",
    "    #y_train = tf.random_shuffle(y_train)\n",
    "    #X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define your architecture here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "import tensorflow as tf \n",
    "with tf.device('/cpu:0'):\n",
    "    EPOCHS = 60\n",
    "    BATCH_SIZE = 128\n",
    "\n",
    "    # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    # Store layers weight & bias\n",
    "\n",
    "    weights = {\n",
    "        'wc1': tf.Variable(tf.random_normal([5, 5, 1, 6], mean = mu, stddev = sigma)),\n",
    "        'wc2': tf.Variable(tf.random_normal([5, 5, 6, 16], mean = mu, stddev = sigma)),\n",
    "        'wd1': tf.Variable(tf.random_normal([5*5*16, 120], mean = mu, stddev = sigma)),\n",
    "        'wd2': tf.Variable(tf.random_normal([120, 84], mean = mu, stddev = sigma)),\n",
    "        'out': tf.Variable(tf.random_normal([84, n_classes], mean = mu, stddev = sigma))}\n",
    "\n",
    "    biases = {\n",
    "        'bc1': tf.Variable(tf.random_normal([6])),\n",
    "        'bc2': tf.Variable(tf.random_normal([16])),\n",
    "        'bd1': tf.Variable(tf.random_normal([120])),\n",
    "        'bd2': tf.Variable(tf.random_normal([84])),\n",
    "        'out': tf.Variable(tf.random_normal([n_classes]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "def LeNet(x):\n",
    "\n",
    "    # Layer 1: Convolutional. Input = 32x32x1. Output = 28x28x6.\n",
    "    strides = 1\n",
    "    conv1 = tf.nn.conv2d(x, weights['wc1'], strides=[1, strides, strides, 1], padding='VALID')\n",
    "    conv1 = tf.nn.bias_add(conv1, biases['bc1'])\n",
    "    # Activation.\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    # Dropout\n",
    "    #conv1 = tf.nn.dropout(conv1, keep_prob=0.1)\n",
    "    # Pooling. Input = 28x28x6. Output = 14x14x6.\n",
    "    k = 2\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='VALID')\n",
    "\n",
    "    # Layer 2: Convolutional. Output = 10x10x16.\n",
    "    conv2 = tf.nn.conv2d(conv1, weights['wc2'], strides=[1, strides, strides, 1], padding='VALID')\n",
    "    conv2 = tf.nn.bias_add(conv2, biases['bc2'])\n",
    "    # Activation.\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    # Dropout\n",
    "    #conv2 = tf.nn.dropout(conv2, keep_prob=0.1)\n",
    "    # Pooling. Input = 10x10x16. Output = 5x5x16.\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='VALID')\n",
    "    # Flatten. Input = 5x5x16. Output = 400.\n",
    "    flatten = tf.contrib.layers.flatten(conv2)\n",
    "    \n",
    "    # Layer 3: Fully Connected. Input = 400. Output = 120.\n",
    "    fc1 = tf.add(tf.matmul(flatten, weights['wd1']), biases['bd1'])\n",
    "    # Activation.\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    # Dropout\n",
    "    #fc1 = tf.nn.dropout(fc1, keep_prob=0.5)\n",
    "    \n",
    "    # Layer 4: Fully Connected. Input = 120. Output = 84.\n",
    "    fc2 = tf.add(tf.matmul(fc1, weights['wd2']), biases['bd2'])\n",
    "    # Activation.\n",
    "    fc2 = tf.nn.relu(fc2)\n",
    "     # Dropout\n",
    "    #fc2 = tf.nn.dropout(fc2, keep_prob=0.5)\n",
    "    \n",
    "    # Layer 5: Fully Connected. Input = 84. Output = 43   \n",
    "    logits = tf.add(tf.matmul(fc2, weights['out']), biases['out'])\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 32, 32, 1))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "one_hot_y = tf.one_hot(y, n_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = 0.001\n",
    "\n",
    "logits = LeNet(x)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=one_hot_y, logits=logits)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "#optimizer = tf.train.GradientDescentOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Validate and Test the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A validation set can be used to assess how well the model is performing. A low accuracy on the training and validation\n",
    "sets imply underfitting. A high accuracy on the training set but low accuracy on the validation set implies overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train your model here.\n",
    "### Calculate and report the accuracy on the training and validation set.\n",
    "### Once a final model architecture is selected, \n",
    "### the accuracy on the test set should be calculated and reported as well.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.7985922 ]\n",
      "  [-0.8064039 ]\n",
      "  [-0.80729455]\n",
      "  ...\n",
      "  [-0.77549374]\n",
      "  [-0.7815242 ]\n",
      "  [-0.78063357]]\n",
      "\n",
      " [[-0.7907805 ]\n",
      "  [-0.80181795]\n",
      "  [-0.80181795]\n",
      "  ...\n",
      "  [-0.77549374]\n",
      "  [-0.78241485]\n",
      "  [-0.7838594 ]]\n",
      "\n",
      " [[-0.792225  ]\n",
      "  [-0.80181795]\n",
      "  [-0.80415314]\n",
      "  ...\n",
      "  [-0.77549374]\n",
      "  [-0.78241485]\n",
      "  [-0.7838594 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.8064039 ]\n",
      "  [-0.7985922 ]\n",
      "  [-0.7939219 ]\n",
      "  ...\n",
      "  [-0.8064039 ]\n",
      "  [-0.8049594 ]\n",
      "  [-0.79803824]]\n",
      "\n",
      " [[-0.80865467]\n",
      "  [-0.800843  ]\n",
      "  [-0.7915867 ]\n",
      "  ...\n",
      "  [-0.8064039 ]\n",
      "  [-0.8049594 ]\n",
      "  [-0.80585   ]]\n",
      "\n",
      " [[-0.80631953]\n",
      "  [-0.7985078 ]\n",
      "  [-0.7947281 ]\n",
      "  ...\n",
      "  [-0.80729455]\n",
      "  [-0.8127711 ]\n",
      "  [-0.8205828 ]]] 41\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "session_conf = tf.ConfigProto(\n",
    "    device_count={'CPU' : 1, 'GPU' : 0},\n",
    "    allow_soft_placement=True,\n",
    "    log_device_placement=False\n",
    ")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = ''\n",
    "with tf.device('/cpu:0'):\n",
    "    #X_train_dataset = tf.data.Dataset.from_tensor_slices(X_train_tensor)\n",
    "    #X_train_dataset = X_train_dataset.prefetch(1)\n",
    "    #iter = X_train_dataset.make_initializable_iterator()\n",
    "    #el = iter.get_next()\n",
    "    with tf.Session(config = session_conf) as sess:    \n",
    "        #sess.run(iter.initializer)\n",
    "        X_train = sess.run(X_train)\n",
    "        y_train = sess.run(y_train)\n",
    "        \n",
    "        X_valid = sess.run(X_valid)\n",
    "        X_test = sess.run(X_test)\n",
    "        #print(sess.run(el))\n",
    "        #print(sess.run(el))\n",
    "       # print(sess.run(el))\n",
    "    print(X_train[0], y_train[0])\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "EPOCH 1 ...\n",
      "Training Accuracy = 0.573\n",
      "Validation Accuracy = 0.632\n",
      "\n",
      "EPOCH 2 ...\n",
      "Training Accuracy = 0.610\n",
      "Validation Accuracy = 0.687\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config_sess = tf.ConfigProto(allow_soft_placement=True, log_device_placement=True) \n",
    "config_sess.gpu_options.allow_growth = True\n",
    "with tf.device('/device:GPU:0'):\n",
    "    with tf.Session(config = config_sess) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        #num_examples = len(X_train)\n",
    "        num_examples = X_train.shape[0]\n",
    "\n",
    "        print(\"Training...\")\n",
    "        print()\n",
    "        for i in range(EPOCHS):\n",
    "            X_train, y_train = shuffle(X_train, y_train)\n",
    "            #X_train, y_train = tf.random_shuffle(X_train), tf.random_shuffle(y_train)\n",
    "\n",
    "            for offset in range(0, num_examples, BATCH_SIZE):\n",
    "                end = offset + BATCH_SIZE\n",
    "                batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "                #batch_x, batch_y = sess.run([batch_x, batch_y])\n",
    "                #batch_x.eval(sess)\n",
    "\n",
    "                #batch_y = np.array(batch_y[0])\n",
    "                #batch_y = sess.run(batch_y)\n",
    "                #batch_x = sess.run(batch_x)\n",
    "                #print(batch_y)\n",
    "                #print(batch_x)\n",
    "\n",
    "                sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "\n",
    "\n",
    "            training_accuracy = evaluate(X_train, y_train)\n",
    "            validation_accuracy = evaluate(X_valid, y_valid)\n",
    "            print(\"EPOCH {} ...\".format(i+1))\n",
    "            print(\"Training Accuracy = {:.3f}\".format(training_accuracy))\n",
    "            print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "            print()\n",
    "\n",
    "        saver.save(sess, './traffic_sign_classifier')\n",
    "        print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./traffic_sign_classifier\n",
      "Test Accuracy = 0.760\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "\n",
    "    test_accuracy = evaluate(X_test, y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Test a Model on New Images\n",
    "\n",
    "To give yourself more insight into how your model is working, download at least five pictures of German traffic signs from the web and use your model to predict the traffic sign type.\n",
    "\n",
    "You may find `signnames.csv` useful as it contains mappings from the class id (integer) to the actual sign name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Output the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the images and plot them here.\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the Sign Type for Each Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run the predictions here and use the model to output the prediction for each image.\n",
    "### Make sure to pre-process the images with the same pre-processing pipeline used earlier.\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate the accuracy for these 5 new images. \n",
    "### For example, if the model predicted 1 out of 5 signs correctly, it's 20% accurate on these new images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Top 5 Softmax Probabilities For Each Image Found on the Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the new images, print out the model's softmax probabilities to show the **certainty** of the model's predictions (limit the output to the top 5 probabilities for each image). [`tf.nn.top_k`](https://www.tensorflow.org/versions/r0.12/api_docs/python/nn.html#top_k) could prove helpful here. \n",
    "\n",
    "The example below demonstrates how tf.nn.top_k can be used to find the top k predictions for each image.\n",
    "\n",
    "`tf.nn.top_k` will return the values and indices (class ids) of the top k predictions. So if k=3, for each sign, it'll return the 3 largest probabilities (out of a possible 43) and the correspoding class ids.\n",
    "\n",
    "Take this numpy array as an example. The values in the array represent predictions. The array contains softmax probabilities for five candidate images with six possible classes. `tf.nn.top_k` is used to choose the three classes with the highest probability:\n",
    "\n",
    "```\n",
    "# (5, 6) array\n",
    "a = np.array([[ 0.24879643,  0.07032244,  0.12641572,  0.34763842,  0.07893497,\n",
    "         0.12789202],\n",
    "       [ 0.28086119,  0.27569815,  0.08594638,  0.0178669 ,  0.18063401,\n",
    "         0.15899337],\n",
    "       [ 0.26076848,  0.23664738,  0.08020603,  0.07001922,  0.1134371 ,\n",
    "         0.23892179],\n",
    "       [ 0.11943333,  0.29198961,  0.02605103,  0.26234032,  0.1351348 ,\n",
    "         0.16505091],\n",
    "       [ 0.09561176,  0.34396535,  0.0643941 ,  0.16240774,  0.24206137,\n",
    "         0.09155967]])\n",
    "```\n",
    "\n",
    "Running it through `sess.run(tf.nn.top_k(tf.constant(a), k=3))` produces:\n",
    "\n",
    "```\n",
    "TopKV2(values=array([[ 0.34763842,  0.24879643,  0.12789202],\n",
    "       [ 0.28086119,  0.27569815,  0.18063401],\n",
    "       [ 0.26076848,  0.23892179,  0.23664738],\n",
    "       [ 0.29198961,  0.26234032,  0.16505091],\n",
    "       [ 0.34396535,  0.24206137,  0.16240774]]), indices=array([[3, 0, 5],\n",
    "       [0, 1, 4],\n",
    "       [0, 5, 1],\n",
    "       [1, 3, 5],\n",
    "       [1, 4, 3]], dtype=int32))\n",
    "```\n",
    "\n",
    "Looking just at the first row we get `[ 0.34763842,  0.24879643,  0.12789202]`, you can confirm these are the 3 largest probabilities in `a`. You'll also notice `[3, 0, 5]` are the corresponding indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Print out the top five softmax probabilities for the predictions on the German traffic sign images found on the web. \n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Writeup\n",
    "\n",
    "Once you have completed the code implementation, document your results in a project writeup using this [template](https://github.com/udacity/CarND-Traffic-Sign-Classifier-Project/blob/master/writeup_template.md) as a guide. The writeup can be in a markdown or pdf file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**: Once you have completed all of the code implementations and successfully answered each question above, you may finalize your work by exporting the iPython Notebook as an HTML document. You can do this by using the menu above and navigating to  \\n\",\n",
    "    \"**File -> Download as -> HTML (.html)**. Include the finished document along with this notebook as your submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 4 (Optional): Visualize the Neural Network's State with Test Images\n",
    "\n",
    " This Section is not required to complete but acts as an additional excersise for understaning the output of a neural network's weights. While neural networks can be a great learning device they are often referred to as a black box. We can understand what the weights of a neural network look like better by plotting their feature maps. After successfully training your neural network you can see what it's feature maps look like by plotting the output of the network's weight layers in response to a test stimuli image. From these plotted feature maps, it's possible to see what characteristics of an image the network finds interesting. For a sign, maybe the inner network feature maps react with high activation to the sign's boundary outline or to the contrast in the sign's painted symbol.\n",
    "\n",
    " Provided for you below is the function code that allows you to get the visualization output of any tensorflow weight layer you want. The inputs to the function should be a stimuli image, one used during training or a new one you provided, and then the tensorflow variable name that represents the layer's state during the training process, for instance if you wanted to see what the [LeNet lab's](https://classroom.udacity.com/nanodegrees/nd013/parts/fbf77062-5703-404e-b60c-95b78b2f3f9e/modules/6df7ae49-c61c-4bb2-a23e-6527e69209ec/lessons/601ae704-1035-4287-8b11-e2c2716217ad/concepts/d4aca031-508f-4e0b-b493-e7b706120f81) feature maps looked like for it's second convolutional layer you could enter conv2 as the tf_activation variable.\n",
    "\n",
    "For an example of what feature map outputs look like, check out NVIDIA's results in their paper [End-to-End Deep Learning for Self-Driving Cars](https://devblogs.nvidia.com/parallelforall/deep-learning-self-driving-cars/) in the section Visualization of internal CNN State. NVIDIA was able to show that their network's inner weights had high activations to road boundary lines by comparing feature maps from an image with a clear path to one without. Try experimenting with a similar test to show that your trained network's weights are looking for interesting features, whether it's looking at differences in feature maps from images with or without a sign, or even what feature maps look like in a trained network vs a completely untrained one on the same sign image.\n",
    "\n",
    "<figure>\n",
    " <img src=\"visualize_cnn.png\" width=\"380\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Your output should look something like this (above)</p> \n",
    " </figcaption>\n",
    "</figure>\n",
    " <p></p> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualize your network's feature maps here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "# image_input: the test image being fed into the network to produce the feature maps\n",
    "# tf_activation: should be a tf variable name used during your training procedure that represents the calculated state of a specific weight layer\n",
    "# activation_min/max: can be used to view the activation contrast in more detail, by default matplot sets min and max to the actual min and max values of the output\n",
    "# plt_num: used to plot out multiple different weight feature map sets on the same block, just extend the plt number for each new feature map entry\n",
    "\n",
    "def outputFeatureMap(image_input, tf_activation, activation_min=-1, activation_max=-1 ,plt_num=1):\n",
    "    # Here make sure to preprocess your image_input in a way your network expects\n",
    "    # with size, normalization, ect if needed\n",
    "    # image_input =\n",
    "    # Note: x should be the same name as your network's tensorflow data placeholder variable\n",
    "    # If you get an error tf_activation is not defined it may be having trouble accessing the variable from inside a function\n",
    "    activation = tf_activation.eval(session=sess,feed_dict={x : image_input})\n",
    "    featuremaps = activation.shape[3]\n",
    "    plt.figure(plt_num, figsize=(15,15))\n",
    "    for featuremap in range(featuremaps):\n",
    "        plt.subplot(6,8, featuremap+1) # sets the number of feature maps to show on each row and column\n",
    "        plt.title('FeatureMap ' + str(featuremap)) # displays the feature map number\n",
    "        if activation_min != -1 & activation_max != -1:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", vmin =activation_min, vmax=activation_max, cmap=\"gray\")\n",
    "        elif activation_max != -1:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", vmax=activation_max, cmap=\"gray\")\n",
    "        elif activation_min !=-1:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", vmin=activation_min, cmap=\"gray\")\n",
    "        else:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputFeatureMap(x, conv2, activation_min=-1, activation_max=-1 ,plt_num=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
